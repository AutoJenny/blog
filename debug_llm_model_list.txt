 id |           name           | provider_id |           description            |                 strengths                  |              weaknesses              |         api_params          |         created_at         |         updated_at         
----+--------------------------+-------------+----------------------------------+--------------------------------------------+--------------------------------------+-----------------------------+----------------------------+----------------------------
  1 | mistral                  |           1 | Mistral 7B (local)               | Fast, low resource, good for general tasks | Not as strong as GPT-4 for reasoning | {"max_tokens": 8192}        | 2025-05-26 11:02:54.337827 | 2025-05-26 11:02:54.337827
  2 | gpt-3.5-turbo            |           2 | OpenAI GPT-3.5 Turbo             | Fast, cheap, good for general tasks        | Not as strong as GPT-4 for reasoning | {"max_tokens": 16384}       | 2025-05-26 11:07:20.603016 | 2025-05-26 11:07:20.603016
  3 | gpt-4-turbo              |           2 | OpenAI GPT-4 Turbo               | Strong reasoning, broad knowledge          | Slower, more expensive               | {"max_tokens": 128000}      | 2025-05-26 11:07:20.603016 | 2025-05-26 11:07:20.603016
  4 | gpt-4o                   |           2 | OpenAI GPT-4o                    | Fast, multimodal, strong reasoning         | New, less tested                     | {"max_tokens": 128000}      | 2025-05-26 11:07:20.603016 | 2025-05-26 11:07:20.603016
  5 | claude-3-opus-20240229   |           3 | Anthropic Claude 3 Opus          | Very strong reasoning, long context        | Expensive, slower                    | {"max_tokens": 200000}      | 2025-05-26 11:07:20.604904 | 2025-05-26 11:07:20.604904
  6 | claude-3-sonnet-20240229 |           3 | Anthropic Claude 3 Sonnet        | Strong, fast, cheaper than Opus            | Slightly less capable                | {"max_tokens": 200000}      | 2025-05-26 11:07:20.604904 | 2025-05-26 11:07:20.604904
  7 | claude-3-haiku-20240307  |           3 | Anthropic Claude 3 Haiku         | Fastest, cheapest Claude                   | Lower reasoning ability              | {"max_tokens": 200000}      | 2025-05-26 11:07:20.604904 | 2025-05-26 11:07:20.604904
  8 | gemini-1.5-pro           |           4 | Google Gemini 1.5 Pro            | Multimodal, long context                   | New, less tested                     | {"max_tokens": 1048576}     | 2025-05-26 11:07:20.605505 | 2025-05-26 11:07:20.605505
  9 | gemini-1.0-pro           |           4 | Google Gemini 1.0 Pro            | Good for general tasks                     | Not as strong as GPT-4               | {"max_tokens": 32768}       | 2025-05-26 11:07:20.605505 | 2025-05-26 11:07:20.605505
 10 | llama3.1:70b             |           1 | Llama 3.1 70B (Ollama)           | Large, strong reasoning                    | High resource usage                  | {"parameter_size": "70.6B"} | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 11 | deepseek-coder:latest    |           1 | DeepSeek Coder (Ollama)          | Code generation                            | Small context                        | {"parameter_size": "1B"}    | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 12 | nomic-embed-text:latest  |           1 | Nomic Embed Text (Ollama)        | Embeddings                                 | Not a chat model                     | {"parameter_size": "137M"}  | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 13 | qwen2.5-coder:1.5b-base  |           1 | Qwen2.5 Coder 1.5B Base (Ollama) | Code, small model                          | Lower reasoning                      | {"parameter_size": "1.5B"}  | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 14 | llama3.1:8b              |           1 | Llama 3.1 8B (Ollama)            | Fast, low resource                         | Lower accuracy                       | {"parameter_size": "8.0B"}  | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 15 | qwq:32b                  |           1 | QWQ 32B (Ollama)                 | Large, strong reasoning                    | High resource usage                  | {"parameter_size": "32.8B"} | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 16 | llama3.2:latest          |           1 | Llama 3.2 (Ollama)               | General tasks                              | Small context                        | {"parameter_size": "3.2B"}  | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 17 | qwen2.5:1.5b             |           1 | Qwen2.5 1.5B (Ollama)            | Small, fast                                | Lower reasoning                      | {"parameter_size": "1.5B"}  | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 18 | aya:35b                  |           1 | Aya 35B (Ollama)                 | Large, strong reasoning                    | High resource usage                  | {"parameter_size": "35.0B"} | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 19 | qwen2.5:32b              |           1 | Qwen2.5 32B (Ollama)             | Large, strong reasoning                    | High resource usage                  | {"parameter_size": "32.8B"} | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 20 | llama3:latest            |           1 | Llama 3 (Ollama)                 | General tasks                              | Small context                        | {"parameter_size": "8B"}    | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 21 | mistral:latest           |           1 | Mistral 7B (Ollama)              | Fast, low resource                         | Lower accuracy                       | {"parameter_size": "7B"}    | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 22 | llava:latest             |           1 | Llava (Ollama)                   | Multimodal                                 | Experimental                         | {"parameter_size": "7B"}    | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
 23 | mixtral:latest           |           1 | Mixtral (Ollama)                 | Large, strong reasoning                    | High resource usage                  | {"parameter_size": "47B"}   | 2025-05-26 11:07:20.605884 | 2025-05-26 11:07:20.605884
(23 rows)

